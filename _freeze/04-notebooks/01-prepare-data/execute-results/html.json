{
  "hash": "6926a1d112670acc44b48720f62e295a",
  "result": {
    "markdown": "---\ntitle: \"Prepare data\"\nfreeze: auto\ndate: \"2024-05-07\"\n---\n\n\n# Prepare data with EDA\n\nThis notebook sets an example workflow and template for preparing raw data for analysis. The focus is on cleaning, coding, and transforming the data, which are crucial steps to ensure the reliability and validity of the analysis. All processing steps should be documented, including the determination of the sample size, any data exclusions, manipulations, and the creation of variables for the study.\n\n**EDA (Exploratory Data Analysis)** is integrated into the process to understand the distribution of the data and identify any issues that need addressing. After processing, the processed data is saved in CSV format. This approach keeps the raw data untouched and makes all processing steps transparent and reproducible.\n\n\n```{mermaid}\nflowchart LR\n    step0(\"Load<br> raw data\") -->\n    step1(\"Modify<br> Data Types\") -->\n    step2(\"Initial<br> EDA\") -->\n    step3(\"Data<br> Cleaning\") -->\n    step4(\"Data<br> Transformations\") -->\n    step5(\"Post-Cleaning<br> EDA\") -->\n    step6(\"Save <br>the data\")\n```\n\n\n**Why prepare data in a notebook instead of a script file?**\n\n-   Working in a notebook, rather than a script file, allows for the inclusion of exploratory data analysis and personal notes while processing data to ensure accurate processing. With the \"purl\" function, explained in the [**Babysteps tutorial**](../babysteps), only the code chunks will be extracted and saved in a script file for public sharing. The full notebook is intended for personal and collegial use. Feel free to modify the notebook for your style and purposes.\n\n## 1 Load raw data and packages\n\n**Overview:** Start by loading required R packages and the dataset into your analysis environment. For the tutorial, we load the raw data created in the [Simulate-data notebook](00-simulate-data).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"View code: Load packages and data\"}\n# Load required packages\nrequire(here)\nrequire(tidyverse)\n\n# Load / download data\nif (file.exists(here(\"01-data/raw/babysteps-rawdata.csv\"))) {\n  dataset <- read.csv(here(\"01-data/raw/babysteps-rawdata.csv\"))\n} else {\n  dataset <-\n    read.csv(\n      \"https://raw.githubusercontent.com/juusorepo/ReproRepo/master/01-data/raw/babysteps-rawdata.csv\"\n    )\n}\n```\n:::\n\n\n## Check and Modify Data Types\n\nBefore diving into EDA, it's crucial to ensure that each variable in your dataset is stored in the most appropriate data type. Correct data types can improve computational efficiency and are essential for appropriate analysis techniques.\n\n-   **Action Steps:** Start by listing the current data types of variables in your dataset. This helps identify any variables that may be incorrectly typed, such as numeric variables recognized as character data due to formatting issues.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Display the current data types of all variables in the dataset\nstr(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t300 obs. of  7 variables:\n $ BabyID     : int  1 1 1 2 2 2 3 3 3 4 ...\n $ StepType   : chr  \"Walking\" \"Walking\" \"Walking\" \"Walking\" ...\n $ AgeMonths  : int  18 18 18 17 17 17 21 21 21 16 ...\n $ Wave       : chr  \"T1\" \"T2\" \"T3\" \"T1\" ...\n $ SleepHours : int  9 9 9 9 8 7 14 13 15 14 ...\n $ PuzzleTime : int  49 47 48 43 48 35 54 41 55 80 ...\n $ GiggleCount: int  4 4 4 4 4 4 4 4 4 4 ...\n```\n:::\n:::\n\n\n-   **Convert Data Types:** Based on the initial inspection, we convert variables to their correct data types. Common conversions include transforming character variables that represent categories into factors and ensuring numeric variables are not mistakenly treated as character or factor types.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Converting character variables to factors\ndataset <- dataset %>% mutate_if(is.character, as.factor)\n```\n:::\n\n\n## Initial Exploratory Data Analysis\n\nBefore further processing, you may want to conduct an exploratory data analysis (EDA) to gain insights into the dataset's distribution and characteristics. There are various ways to do this and also packages for automated EDA analysis (e.g., DataExplorer, GGally, SmartEDA, Hmisc). For this tutorial, we use the DataExplorer, which works fine for smaller datasets.\n\n-   **Action Steps:** Run the code below to create an EDA report. See results in Notebooks folder or [here](EDA-report-initial-2024-03-21.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load/Install DataExplorer package\nif (!requireNamespace(\"DataExplorer\", quietly = TRUE)) {install.packages(\"DataExplorer\")}\nrequire(DataExplorer)\n\n# Create the report\ndataset %>%\n    create_report(\n        output_file = paste(\"EDA-report-initial\", Sys.Date(), sep=\"-\"), # filename\n        report_title = \"Initial EDA Report - Babysteps Dataset\",\n        y = 'PuzzleTime' # to set the outcome variable\n    )\nmessage(\"The EDA report was created and saved in your notebooks folder\")\n```\n:::\n\n\n## Data Cleaning\n\nThis step involves identifying and correcting issues in your dataset, such as missing values, errors, outliers, and standardizing variable names, to ensure data quality.\n\n### Identifying Missing Values\n\n-   **Overview:** Begin by identifying missing values in your dataset. Missing data can occur for various reasons, from non-response in surveys to errors in data entry.\n-   **Action Steps:** Use descriptive statistics to identify missing patterns and decide on appropriate methods for handling them, such as imputation or exclusion, based on the nature of your data.\n\n\n\n\n\n### Correcting Errors\n\n-   **Overview:** Data entry errors, inconsistencies in response formats, and other inaccuracies can significantly affect your analysis.\n-   **Action Steps:** Validate data ranges (e.g., ages within plausible limits) and consistency (e.g., gender coded uniformly). Correct identified errors where possible, or note them for exclusion or special consideration.\n\n\n::: {.cell}\n\n:::\n\n\n### Handling Outliers\n\n-   **Overview:** Outliers can influence statistical analyses and may represent either genuine phenomena or data errors.\n-   **Action Steps:** Identify outliers through visual (e.g., boxplots) and statistical methods. Investigate their origins and decide whether to keep, adjust, or remove them, documenting your rationale.\n\n\n::: {.cell}\n\n:::\n\n\n### **Standardize Variable Names**\n\nEnsure all variable names are in lowercase to maintain consistency across your dataset. This can help avoid case-sensitive errors in your analysis scripts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lowercase all variables (good practice)\ndataset <- dataset %>% rename_all(tolower)\n```\n:::\n\n\n*Tip. Check out clean.names() function from janitor package to clean up variable names.*\n\n## Data Recoding and Transformation\n\nThis step encompasses the processes of adjusting your variables to better fit your analysis needs and preparing your data through various transformations. It ensures that your dataset is in the optimal form for analysis, addressing both the structure of your data and the scales of measurement.\n\n### Recoding Variables\n\n-   **Overview:** Recoding involves adjusting existing variables to better fit your analysis needs, such as combining categories of a nominal variable or changing measurement scales.\n-   **Action Steps:** Clearly define your recoding rules and apply them uniformly across your dataset. Document changes to ensure transparency and reproducibility.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recode wave into an integer for regression analyses\ndataset$wave <- as.integer(gsub(\"T\", \"\", dataset$wave))\n\n# create a new categorical variable AgeGroup\ndataset <- dataset %>%\n  mutate(agegroup = case_when(\n    agemonths <= 14 ~ \"12-14 months\",\n    agemonths <= 20 ~ \"15-20 months\",\n    TRUE ~ \"21-24 months\"\n  ))\n```\n:::\n\n\n### Normalizing Scales\n\n-   **Overview:** Variable scales may need normalization, especially when combining data from different sources or preparing for certain statistical analyses.\n-   **Action Steps:** Apply normalization techniques, such as z-score standardization or min-max scaling, to adjust scales. Choose a method appropriate for your data distribution and analysis requirements.\n\n### Creating Dummy Variables\n\n-   **Overview:** Dummy variables are used to represent categorical data in binary form, which is necessary for many types of statistical modeling.\n-   **Action Steps:** Convert categorical variables into dummy variables as needed.\n\n## Post-Cleaning EDA\n\nAfter cleaning and transforming your data, perform another round of EDA to verify the data preparation steps' effects and ensure the dataset is ready for analysis. Look for any remaining issues to check the data quality and structure post-cleaning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the EDA report, define the outcome variable\ndataset %>%\n    create_report(\n        output_file = paste(\"EDA-report-processed\", Sys.Date(), sep=\" - \"),\n        report_title = \"EDA Report with processed data - Babysteps Dataset\",\n        y = 'puzzletime'\n    )\nmessage(\"The EDA report was created and saved in your notebooks folder\")\n```\n:::\n\n\n## Save the processed data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save in CSV format into processed data -subfolder\nwrite.csv(dataset, here(\"01-data/processed/babysteps.csv\"), row.names = FALSE)\nmessage(\"The processed dataset was saved in processed data folder\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThe processed dataset was saved in processed data folder\n```\n:::\n:::\n\n\n# Conclusion\n\nThis workflow guides you from loading your data to ensuring it's analytically ready, highlighting the iterative nature of data preparation. By incorporating initial and post-cleaning EDA, you continuously validate your steps and decisions, enhancing the quality of your research.\n\n**To follow the full tutorial, next step is [Creating reproducible outputs](../babysteps#step2c)**\n",
    "supporting": [
      "01-prepare-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}